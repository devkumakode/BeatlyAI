{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the tutorial for transformers from pytorch docs.\n",
    "\n",
    "Compared to Recurrent Neural Networks (RNNs), the transformer model has proven to be superior in quality for many sequence-to-sequence tasks while being more parallelizable.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "# q: what is TemporaryDirectory?\n",
    "# a: https://docs.python.org/3/library/tempfile.html#tempfile.TemporaryDirectory\n",
    "# used to create a temporary directory using the context manager\n",
    "from typing import Tuple\n",
    "# q: explain typing\n",
    "# a: https://docs.python.org/3/library/typing.html#module-typing\n",
    "# q: what is Tuple?\n",
    "# a: https://docs.python.org/3/library/typing.html#typing.Tuple\n",
    "# provide runtime support for type hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nn.TransformerEncoder consists of multiple layers of nn.TransformerEncoderLayer. Along with the input sequence, a square attention mask is required because the self-attention layers in nn.TransformerDecoder are only allowed to attend the earlier positions in the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Model (Encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the transformer model\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken:int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        \n",
    "        # q: Explain ntoken, d_model, nhead, d_hid, nlayers, dropout\n",
    "        # a: ntoken: the size of vocabulary\n",
    "        #    d_model: the dimension of the embedding vector\n",
    "        #    nhead: the number of heads in the multi-head attention models\n",
    "        #    d_hid: the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "        #    nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "        #    dropout: the dropout value. (Dropping out nodes in the network temporarily)\n",
    "\n",
    "        # q: Explain nn.TransformerEncoder and nn.TransformerEncoderLayer\n",
    "        # a: nn.TransformerEncoder: TransformerEncoder is a stack of N encoder layers\n",
    "        #    nn.TransformerEncoderLayer: TransformerEncoderLayer is made up of self-attn and feedforward network\n",
    "\n",
    "\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.embedding = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.linear = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        #self.init_weights()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        # Draws a random sample from a uniform distribution within [-initrange, initrange]\n",
    "\n",
    "        self.linear.bias.data.zero_()\n",
    "        # set the bias tensor to zero\n",
    "\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "        # Draws a random sample from a uniform distribution within [-initrange, initrange]\n",
    "\n",
    "    def forward(self, src: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape ``[seq_len, batch_size]``\n",
    "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n",
    "        \"\"\"\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PositionalEncoding module injects some information about the relative or absolute position of the tokens in the sequence. The positional encodings have the same dimension as the embeddings so that the two can be summed. Here, we use sine and cosine functions of different frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and batch data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using torchtext to generate Wikitext-2 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: portalocker in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (2.7.0)\n",
      "Requirement already satisfied: torchdata in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (0.6.1)\n",
      "Requirement already satisfied: torch==2.0.1 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torchdata) (2.0.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torchdata) (1.26.16)\n",
      "Requirement already satisfied: requests in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torchdata) (2.31.0)\n",
      "Requirement already satisfied: filelock in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torch==2.0.1->torchdata) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torch==2.0.1->torchdata) (4.6.3)\n",
      "Requirement already satisfied: sympy in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torch==2.0.1->torchdata) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torch==2.0.1->torchdata) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torch==2.0.1->torchdata) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from jinja2->torch==2.0.1->torchdata) (2.1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from requests->torchdata) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from requests->torchdata) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from requests->torchdata) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from sympy->torch==2.0.1->torchdata) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pip install portalocker\n",
    "pip install torchdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocab object is built based on the train dataset and is used to numericalize tokens into tensors. Wikitext-2 represents rare tokens as <unk>.\n",
    "\n",
    "Given a 1-D vector of sequential data, batchify() arranges the data into batch_size columns. If the data does not divide evenly into batch_size columns, then the data is trimmed to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: torchdata==0.6.1 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torchtext) (0.6.1)\n",
      "Requirement already satisfied: tqdm in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torchtext) (4.66.1)\n",
      "Requirement already satisfied: requests in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torchtext) (2.31.0)\n",
      "Requirement already satisfied: torch==2.0.1 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torchtext) (2.0.1)\n",
      "Requirement already satisfied: numpy in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torchtext) (1.24.3)\n",
      "Requirement already satisfied: filelock in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torch==2.0.1->torchtext) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torch==2.0.1->torchtext) (4.6.3)\n",
      "Requirement already satisfied: sympy in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torch==2.0.1->torchtext) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torch==2.0.1->torchtext) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torch==2.0.1->torchtext) (3.1.2)\n",
      "Requirement already satisfied: urllib3>=1.25 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from torchdata==0.6.1->torchtext) (1.26.16)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from jinja2->torch==2.0.1->torchtext) (2.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from requests->torchtext) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from requests->torchtext) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from requests->torchtext) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/hansaalahakoon/miniforge3/envs/TestMac/lib/python3.10/site-packages (from sympy->torch==2.0.1->torchtext) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "train_iter = WikiText2(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
    "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "# ``train_iter`` was \"consumed\" by the process of building the vocab,\n",
    "# so we have to create it again\n",
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "train_data = data_process(train_iter)\n",
    "val_data = data_process(val_iter)\n",
    "test_data = data_process(test_iter)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
    "    \"\"\"Divides the data into ``bsz`` separate sequences, removing extra elements\n",
    "    that wouldn't cleanly fit.\n",
    "\n",
    "    Arguments:\n",
    "        data: Tensor, shape ``[N]``\n",
    "        bsz: int, batch size\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape ``[N // bsz, bsz]``\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_data, batch_size)  # shape ``[seq_len, batch_size]``\n",
    "val_data = batchify(val_data, eval_batch_size)\n",
    "test_data = batchify(test_data, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 35\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape ``[full_seq_len, batch_size]``\n",
    "        i: int\n",
    "\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape ``[seq_len, batch_size]`` and\n",
    "        target has shape ``[seq_len * batch_size]``\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate an instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(vocab)  # size of vocabulary\n",
    "emsize = 200  # embedding dimension\n",
    "d_hid = 200  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 2  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 2  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.2  # dropout probability\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model and generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "\n",
    "    num_batches = len(train_data) // bptt\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        output = model(data)\n",
    "        output_flat = output.view(-1, ntokens)\n",
    "        loss = criterion(output_flat, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            seq_len = data.size(0)\n",
    "            output = model(data)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(eval_data) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 2928 batches | lr 5.00 | ms/batch 111.21 | loss  8.02 | ppl  3037.40\n",
      "| epoch   1 |   400/ 2928 batches | lr 5.00 | ms/batch 107.58 | loss  6.73 | ppl   837.65\n",
      "| epoch   1 |   600/ 2928 batches | lr 5.00 | ms/batch 110.58 | loss  6.24 | ppl   511.84\n",
      "| epoch   1 |   800/ 2928 batches | lr 5.00 | ms/batch 19691.16 | loss  6.07 | ppl   431.54\n",
      "| epoch   1 |  1000/ 2928 batches | lr 5.00 | ms/batch 4838.39 | loss  5.93 | ppl   377.97\n",
      "| epoch   1 |  1200/ 2928 batches | lr 5.00 | ms/batch 108.24 | loss  5.90 | ppl   363.83\n",
      "| epoch   1 |  1400/ 2928 batches | lr 5.00 | ms/batch 1214.81 | loss  5.84 | ppl   343.85\n",
      "| epoch   1 |  1600/ 2928 batches | lr 5.00 | ms/batch 2218.28 | loss  5.82 | ppl   338.52\n",
      "| epoch   1 |  1800/ 2928 batches | lr 5.00 | ms/batch 4784.76 | loss  5.71 | ppl   302.37\n",
      "| epoch   1 |  2000/ 2928 batches | lr 5.00 | ms/batch 109.35 | loss  5.68 | ppl   293.47\n",
      "| epoch   1 |  2200/ 2928 batches | lr 5.00 | ms/batch 106.06 | loss  5.54 | ppl   253.84\n",
      "| epoch   1 |  2400/ 2928 batches | lr 5.00 | ms/batch 20062.33 | loss  5.61 | ppl   272.31\n",
      "| epoch   1 |  2600/ 2928 batches | lr 5.00 | ms/batch 8207.89 | loss  5.59 | ppl   266.85\n",
      "| epoch   1 |  2800/ 2928 batches | lr 5.00 | ms/batch 1385.53 | loss  5.49 | ppl   241.38\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 13536.73s | valid loss  5.41 | valid ppl   224.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   200/ 2928 batches | lr 4.75 | ms/batch 14278.02 | loss  5.42 | ppl   226.74\n",
      "| epoch   2 |   400/ 2928 batches | lr 4.75 | ms/batch 19386.16 | loss  5.39 | ppl   218.54\n",
      "| epoch   2 |   600/ 2928 batches | lr 4.75 | ms/batch 6208.82 | loss  5.15 | ppl   172.27\n",
      "| epoch   2 |   800/ 2928 batches | lr 4.75 | ms/batch 110.76 | loss  5.14 | ppl   171.32\n",
      "| epoch   2 |  1000/ 2928 batches | lr 4.75 | ms/batch 111.13 | loss  5.10 | ppl   163.97\n",
      "| epoch   2 |  1200/ 2928 batches | lr 4.75 | ms/batch 113.26 | loss  5.15 | ppl   172.14\n",
      "| epoch   2 |  1400/ 2928 batches | lr 4.75 | ms/batch 107.62 | loss  5.16 | ppl   174.59\n",
      "| epoch   2 |  1600/ 2928 batches | lr 4.75 | ms/batch 116.84 | loss  5.19 | ppl   179.79\n",
      "| epoch   2 |  1800/ 2928 batches | lr 4.75 | ms/batch 112.25 | loss  5.10 | ppl   163.69\n",
      "| epoch   2 |  2000/ 2928 batches | lr 4.75 | ms/batch 113.94 | loss  5.10 | ppl   164.17\n",
      "| epoch   2 |  2200/ 2928 batches | lr 4.75 | ms/batch 117.01 | loss  4.97 | ppl   144.12\n",
      "| epoch   2 |  2400/ 2928 batches | lr 4.75 | ms/batch 117.74 | loss  5.08 | ppl   159.99\n",
      "| epoch   2 |  2600/ 2928 batches | lr 4.75 | ms/batch 127.72 | loss  5.09 | ppl   162.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/hansaalahakoon/Desktop/Projects/e17-4yp-Comprehensive-ECG-analysis-with-Deep-Learning-on-GPU-accelerators/tutorials/hansa/transformer1.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hansaalahakoon/Desktop/Projects/e17-4yp-Comprehensive-ECG-analysis-with-Deep-Learning-on-GPU-accelerators/tutorials/hansa/transformer1.ipynb#X35sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hansaalahakoon/Desktop/Projects/e17-4yp-Comprehensive-ECG-analysis-with-Deep-Learning-on-GPU-accelerators/tutorials/hansa/transformer1.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     epoch_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hansaalahakoon/Desktop/Projects/e17-4yp-Comprehensive-ECG-analysis-with-Deep-Learning-on-GPU-accelerators/tutorials/hansa/transformer1.ipynb#X35sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     train(model)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hansaalahakoon/Desktop/Projects/e17-4yp-Comprehensive-ECG-analysis-with-Deep-Learning-on-GPU-accelerators/tutorials/hansa/transformer1.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     val_loss \u001b[39m=\u001b[39m evaluate(model, val_data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hansaalahakoon/Desktop/Projects/e17-4yp-Comprehensive-ECG-analysis-with-Deep-Learning-on-GPU-accelerators/tutorials/hansa/transformer1.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     val_ppl \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39mexp(val_loss)\n",
      "\u001b[1;32m/Users/hansaalahakoon/Desktop/Projects/e17-4yp-Comprehensive-ECG-analysis-with-Deep-Learning-on-GPU-accelerators/tutorials/hansa/transformer1.ipynb Cell 23\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hansaalahakoon/Desktop/Projects/e17-4yp-Comprehensive-ECG-analysis-with-Deep-Learning-on-GPU-accelerators/tutorials/hansa/transformer1.ipynb#X35sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output_flat, targets)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hansaalahakoon/Desktop/Projects/e17-4yp-Comprehensive-ECG-analysis-with-Deep-Learning-on-GPU-accelerators/tutorials/hansa/transformer1.ipynb#X35sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hansaalahakoon/Desktop/Projects/e17-4yp-Comprehensive-ECG-analysis-with-Deep-Learning-on-GPU-accelerators/tutorials/hansa/transformer1.ipynb#X35sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hansaalahakoon/Desktop/Projects/e17-4yp-Comprehensive-ECG-analysis-with-Deep-Learning-on-GPU-accelerators/tutorials/hansa/transformer1.ipynb#X35sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), \u001b[39m0.5\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hansaalahakoon/Desktop/Projects/e17-4yp-Comprehensive-ECG-analysis-with-Deep-Learning-on-GPU-accelerators/tutorials/hansa/transformer1.ipynb#X35sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniforge3/envs/TestMac/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/TestMac/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 3\n",
    "\n",
    "with TemporaryDirectory() as tempdir:\n",
    "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model)\n",
    "        val_loss = evaluate(model, val_data)\n",
    "        val_ppl = math.exp(val_loss)\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        print('-' * 89)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "        print('-' * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        scheduler.step()\n",
    "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TestMac",
   "language": "python",
   "name": "testmac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
